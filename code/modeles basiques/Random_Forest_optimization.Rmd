---
title: "GLM optimization"
author: "AKROUT Leyth, BOULAHFA Jawad, DE SANTIAGO Kylliann"
date: "22 février 2021"
output:
  prettydoc::html_pretty:
    toc: true
    theme: cayman
    highlight: github
    df_print: paged
---

```{r, echo=FALSE}
rm(list = ls())
```

```{r}
#load(file = "GLM_optimization_final_version.Rdata")
#rm(model_gamma_reactivity, model_gamma_reactivity_pen_ridge, model_gamma_reactivity_pen_enet,
#   model_gamma_deg_Mg_pH10, model_gamma_deg_Mg_pH10_pen_ridge, model_gamma_deg_Mg_pH10_pen_enet,
#   model_gamma_deg_pH10, model_gamma_deg_pH10_pen_ridge, model_gamma_deg_pH10_pen_enet,
#   model_gamma_deg_Mg_50C, model_gamma_deg_Mg_50C_pen_ridge, model_gamma_deg_Mg_50C_pen_enet,
#   model_gamma_deg_50C, model_gamma_deg_50C_pen_ridge, model_gamma_deg_50C_pen_enet)
```


```{r, warning=FALSE, message=FALSE, echo=FALSE}
library(tidyverse)
library(caret)
library(MASS)
library(doParallel) # calcul parallèle
library(glmnet)
library(randomForest)
# source("~/suivi-du-data-camp-DeSantiago_Boulahfa_Akrout/code/projet_fct.R")
source("C:/Users/Startklar/suivi-du-data-camp-DeSantiago_Boulahfa_Akrout/code/projet_fct.R")
# source("./projet_fct.R")
```

```{r}
set.seed(1)
```

# Chargement et réorganisation des données

Chargement du jeu de données.
```{r}
# data = read.csv("~/suivi-du-data-camp-DeSantiago_Boulahfa_Akrout/code/data_train.csv")
data = read.csv("data_train.csv")
head(data) # une colonne en trop
data = data[,-1]
head(data)
```

On change les types des variables qui sont mal codées.
```{r}
data=data %>% mutate(sequence = as.factor(sequence)) %>% 
  mutate(seq_be = as.factor(seq_be)) %>% 
  mutate(seq_af = as.factor(seq_af)) %>% 
  mutate(sequence = as.factor(sequence)) %>% 
  mutate(structure = as.factor(structure)) %>%
  mutate(struct_be = as.factor(struct_be)) %>% 
  mutate(struct_af = as.factor(struct_af)) %>% 
  mutate(predicted_loop_type = as.factor(predicted_loop_type)) %>% 
  mutate(loop_type_be = as.factor(loop_type_be)) %>% 
  mutate(loop_type_af = as.factor(loop_type_af)) 
```

```{r}
length_sequence_train <- 68
```

On filtre maintenant les données qui ont SN_filter=0.
```{r}
print(sum(is.na(data)))
print(sum(data$SN_filter==0)/length_sequence_train) # Nombre d'individus dont le SN_filter=0
data=data[data$SN_filter==1,]
rownames(data)=NULL#1:108052
```

Plutôt que mettre à 0 les valeurs négatives, on va effectuer une translation sur chaque label en soustrayant chacune de ses valeurs par la valeur minimale du label puis en ajoutant un bruit afin de se placer sur $\mathbb{R}_+^*$.
```{r}
p = dim(data)[2]
bruit = 1e-12
```

Initialement, il existe des valeurs négatives pour nos labels.
```{r}
sum(data[,(p-4):p] <= 0) # nb total de lignes où il existe des labels qui ont des valeurs négatives
```

On peut aussi afficher le nombre de lignes où il y a des valeurs négatives pour chacun de nos labels. On peut remarquer que chaque label en possède.
```{r}
sum(data$reactivity <= 0)
sum(data$deg_50C <= 0)
sum(data$deg_Mg_50C <= 0)
sum(data$deg_pH10 <= 0)
sum(data$deg_Mg_pH10 <= 0)
```

On stocke une copie des labels dans un dataframe, afin de pouvoir les utiliser pour calculer les erreurs de prédiction de nos futurs modèles.
```{r}
original_data <- data[, (p-4):p]
```

On effectue une translation pour se placer sur $\mathbb{R}_+^*$.
```{r}
translation_labels <- c()
for (i in (p-4):p)
{
  # On stocke les valeurs utilisées lors des translations de chaque label
  # afin de pouvoir revenir à leurs valeurs initiales
  translation_labels <- c(translation_labels, min(data[,i]) - bruit) 
  # On soustrait à chaque label son minimum (qui est une valeur strictement négative)
  # l'ajout du bruit permet ensuite d'éliminer les valeurs nulles.
  data[,i] <- data[,i] - min(data[,i]) + bruit 
}
translation_labels <- data.frame(t(translation_labels))
colnames(translation_labels) <- colnames(data)[(p-4):p]
```

On a bien retiré toutes les valeurs négatives.
```{r}
sum(data[,(p-4):p] <= 0) # Il n'y a plus aucune valeur négative
```

Il suffira d'ajouter pour chaque label sa valeur dans ce dataframe pour revenir à ses valeurs initiales.
```{r}
translation_labels
```

# Création de la base train/validation

```{r}
tamp=train_test_split(data)
index_train = tamp$index_train

data_train=tamp$train
rownames(data_train) <- NULL

data_val=tamp$val
rownames(data_val) <- NULL

# Valeurs initiales des labels pour le train
original_data_train = original_data[index_train,]
rownames(original_data_train) <- NULL

# Valeurs initiales des labels pour la validation
original_data_val = original_data[-index_train,]
rownames(original_data_val) <- NULL
```

```{r}
sum(is.na(data_train))
sum(is.na(data_val))
dim(data_train)[1]+dim(data_val)[1]-dim(data)[1]
```

```{r}
#rm(tamp,data)
```

# GLM : loi Gamma

Formule du modèle initial utilisé.
```{r}
formula_model_RF <- "reactivity ~ sequence + index_sequence + structure + predicted_loop_type + seq_be + seq_af + struct_be + struct_af + loop_type_be + loop_type_af"
print(formula_model_RF)
```

```{r}
names_coef <- c("(Intercept)", "(Intercept)_", "sequenceC", "sequenceG", "sequenceU",
                "index_sequence", "structure)", "structure.",
                "predicted_loop_typeE", "predicted_loop_typeH", "predicted_loop_typeI",
                "predicted_loop_typeM", "predicted_loop_typeS", "predicted_loop_typeX",
                "seq_beC", "seq_beG", "seq_beO", "seq_beU",
                "seq_afC", "seq_afG", "seq_afO", "seq_afU",
                "struct_be)", "struct_be.", "struct_beO",
                "struct_af)", "struct_af.", "struct_afO",
                "loop_type_beE", "loop_type_beH", "loop_type_beI", "loop_type_beM",
                "loop_type_beO", "loop_type_beS", "loop_type_beX",
                "loop_type_afE", "loop_type_afH", "loop_type_afI", "loop_type_afM",
                "loop_type_afO", "loop_type_afS", "loop_type_afX"
                )
for(i in 0:106)
{
  names_coef <- c(names_coef, paste0("bpps_", i))
}
print(names_coef)
```

ESSAIS

```{r}
names_coef[43] # le premier bpps est à la 43ème position du vecteur
```


## Reactivity

On charge le modèle lasso utilisé précédemment.
```{r}
model_gamma_reactivity_pen_lasso <- readRDS("model_gamma_reactivity_pen_lasso.rds")
```

```{r}
lasso_reactivity_coef <-
  data.frame(matrix(coef(model_gamma_reactivity_pen_lasso, s = 'lambda.min')))
colnames(lasso_reactivity_coef) <- "Coefficients"
rownames(lasso_reactivity_coef) <- names_coef
```

```{r}
zeros_reactivity <- which(apply(lasso_reactivity_coef, 2, function(x) x == 0))
```

On va garder uniquement les features retenues par la modèle lasso vu précédemment pour construire notre modèle Random Forest.
```{r}
formula_model_RF_reactivity = formula_model_RF
for(i in 0:106)
{
  index_bbps_i <- i + 43
  if(!(index_bbps_i %in% zeros_reactivity)) # Si le bpps i n'a pas un coefficient nul dans le lasso
  {
    formula_model_RF_reactivity <- paste0(formula_model_RF_reactivity, " + bpps_", i)
  }
}
print(formula_model_RF_reactivity)
```

```{r}
model_RF_reactivity = randomForest(formula = as.formula(formula_model_RF_reactivity),
                                   data = data_train,
                                   method = "anova",
                                   nodesize = 10,
                                   ntree=3)
```

```{r}
summary(model_RF_reactivity)
```

```{r}
y_pred_RF_train = predict(model_RF_reactivity,data_train,type="response")
error_RF_train <- mean((y_pred_RF_train-data_train$reactivity)^2,na.rm=TRUE)
print(error_RF_train)

y_pred_RF_val=predict(model_RF_reactivity,data_val,type="response")
error_RF_val <- mean((y_pred_RF_val-data_val$reactivity)^2,na.rm=TRUE)
print(error_RF_val)
```





## deg_Mg_pH10


## deg_pH10


## deg_Mg_50C


## deg_50C
